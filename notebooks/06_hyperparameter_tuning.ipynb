{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c91995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE, chi2, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "\n",
    "print(\"Hyperparameter Tuning:\")\n",
    "\n",
    "# Load data\n",
    "df_encoded = pd.read_csv('data/heart_disease.csv')\n",
    "X = df_encoded.drop(\"target\", axis=1)\n",
    "y = df_encoded[\"target\"]\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "\n",
    "# 1) Feature Importance using Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_\n",
    "feat_importances = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# 2) Recursive Feature Elimination (RFE)\n",
    "model = LogReg(max_iter=5000, solver=\"saga\", random_state=42)\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "X_rfe = rfe.fit_transform(X, y)\n",
    "selected_features_rfe = X.columns[rfe.support_]\n",
    "\n",
    "# 3) Chi-Square Test\n",
    "X_chi2 = SelectKBest(score_func=chi2, k=10)\n",
    "X_chi2_fit = X_chi2.fit_transform(X.abs(), y)\n",
    "chi2_features = X.columns[X_chi2.get_support()]\n",
    "\n",
    "# 4) Final reduced dataset\n",
    "selected_features = list(set(selected_features_rfe).union(set(chi2_features)))\n",
    "X_reduced = X[selected_features]\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features\")\n",
    "\n",
    "# SPLIT THE DATA \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reduced, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# Train baseline models quickly for comparison\n",
    "baseline_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "baseline_svm = SVC(probability=True, random_state=42)\n",
    "\n",
    "baseline_rf.fit(X_train, y_train)\n",
    "baseline_svm.fit(X_train, y_train)\n",
    "\n",
    "# Get baseline accuracies\n",
    "y_pred_rf_baseline = baseline_rf.predict(X_test)\n",
    "y_pred_svm_baseline = baseline_svm.predict(X_test)\n",
    "\n",
    "baseline_acc_rf = accuracy_score(y_test, y_pred_rf_baseline)\n",
    "baseline_acc_svm = accuracy_score(y_test, y_pred_svm_baseline)\n",
    "\n",
    "# Create df_results dataframe\n",
    "df_results = pd.DataFrame({\n",
    "    \"Random Forest\": {\"Accuracy\": baseline_acc_rf},\n",
    "    \"SVM\": {\"Accuracy\": baseline_acc_svm}\n",
    "}).T\n",
    "\n",
    "print(f\"Baseline Random Forest Accuracy: {baseline_acc_rf:.3f}\")\n",
    "print(f\"Baseline SVM Accuracy: {baseline_acc_svm:.3f}\")\n",
    "\n",
    "# Hyperparameter Tuning \n",
    "# Reduced parameter grids for faster execution\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 100],\n",
    "    \"max_depth\": [10, None],\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    \"C\": [1, 10],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "}\n",
    "\n",
    "# GridSearchCV for Random Forest\n",
    "print(\"Tuning Random Forest with GridSearchCV\")\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_rf,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "print(\"Random Forest tuning completed!\")\n",
    "\n",
    "# RandomizedSearchCV for SVM\n",
    "print(\"Tuning SVM with RandomizedSearchCV\")\n",
    "rand_svm = RandomizedSearchCV(\n",
    "    SVC(probability=True, random_state=42),\n",
    "    param_distributions=param_grid_svm,\n",
    "    n_iter=2,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rand_svm.fit(X_train, y_train)\n",
    "print(\"SVM tuning completed!\")\n",
    "\n",
    "# Get best models\n",
    "best_rf = grid_rf.best_estimator_\n",
    "best_svm = rand_svm.best_estimator_\n",
    "\n",
    "# Predict with tuned models\n",
    "y_pred_rf_tuned = best_rf.predict(X_test)\n",
    "y_pred_svm_tuned = best_svm.predict(X_test)\n",
    "\n",
    "# Calculate tuned accuracies\n",
    "tuned_acc_rf = accuracy_score(y_test, y_pred_rf_tuned)\n",
    "tuned_acc_svm = accuracy_score(y_test, y_pred_svm_tuned)\n",
    "\n",
    "# Simple comparison table\n",
    "comparison_data = []\n",
    "for model_name in [\"Random Forest\", \"SVM\"]:\n",
    "    if model_name == \"Random Forest\":\n",
    "        baseline_acc = baseline_acc_rf\n",
    "        tuned_acc = tuned_acc_rf\n",
    "        best_params = grid_rf.best_params_\n",
    "    else:\n",
    "        baseline_acc = baseline_acc_svm\n",
    "        tuned_acc = tuned_acc_svm\n",
    "        best_params = rand_svm.best_params_\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Baseline_Accuracy': baseline_acc,\n",
    "        'Tuned_Accuracy': tuned_acc,\n",
    "        'Improvement': tuned_acc - baseline_acc,\n",
    "        'Best_Params': best_params\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\nPerformance Comparison: \")\n",
    "print(df_comparison.round(3))\n",
    "\n",
    "# Deliverable: Best performing model with optimized hyperparameters\n",
    "best_model_row = df_comparison.loc[df_comparison['Tuned_Accuracy'].idxmax()]\n",
    "print(f\"\\nBEST PERFORMING MODEL: {best_model_row['Model']}\")\n",
    "print(f\"OPTIMIZED ACCURACY: {best_model_row['Tuned_Accuracy']:.3f}\")\n",
    "print(f\"OPTIMIZED HYPERPARAMETERS: {best_model_row['Best_Params']}\")\n",
    "\n",
    "# Save the best model\n",
    "if best_model_row['Model'] == \"Random Forest\":\n",
    "    best_model = best_rf\n",
    "else:\n",
    "    best_model = best_svm\n",
    "\n",
    "# Save the model as .pkl file\n",
    "filename = \"models/final_model.pkl\"\n",
    "joblib.dump(best_model, filename)\n",
    "print(f\"Model saved as: {filename}\")\n",
    "\n",
    "\n",
    "# Simple visualization\n",
    "plt.figure(figsize=(8, 5))\n",
    "x = range(len(df_comparison))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar([i - width/2 for i in x], df_comparison['Baseline_Accuracy'], width, \n",
    "        label='Baseline', alpha=0.7, color='skyblue')\n",
    "plt.bar([i + width/2 for i in x], df_comparison['Tuned_Accuracy'], width, \n",
    "        label='Tuned', alpha=0.7, color='lightcoral')\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Baseline vs Tuned Model Performance')\n",
    "plt.xticks(x, df_comparison['Model'])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHyperparameter tuning completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
